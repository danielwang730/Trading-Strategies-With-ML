{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d66510-ed08-4566-8550-959c5257e4a0",
   "metadata": {},
   "source": [
    "# Testing Data Loading from SSD\n",
    "I'm specifically testing 1) whether it's possible, and 2) how fast it is, especially compared with loading data from my local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a1ccfd-b6eb-4c42-b616-e10902bf2997",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e227afe1-8812-47a4-9362-961bab2a6275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from datetime import date\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mlxtend.plotting import heatmap\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask import delayed\n",
    "from pyarrow.parquet import ParquetFile\n",
    "import pyarrow as pa\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tulipy as ti\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import keras_tuner as kt\n",
    "from keras_tuner import HyperParameters\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a41552a-46a5-44de-bc25-fc5a38dc83cd",
   "metadata": {},
   "source": [
    "## Trying to get data from SSD\n",
    "We have our filtered PM 1-min data stored in an SSD, and we're now going to try accessing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70e799aa-36d4-492b-b250-c8029d65af8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/danielwang/Desktop/Work stuff/Coding Stuff/Day Trading Stuff/Trading-Strategies-With-ML/Archive'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the current directory\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f82bb222-4158-4d10-9fd7-341e74b6ac23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Volumes/T7/filtered-parquet-PM'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the path to the SSD\n",
    "ssd_name = 'T7'\n",
    "ssd_path = '/Volumes/' + ssd_name + '/'\n",
    "filtered_parquet_PM_path = ssd_path + 'filtered-parquet-PM/'\n",
    "filtered_parquet_PM_HL_path = ssd_path + 'filtered-parquet-PM-HL/'\n",
    "\n",
    "# Changing the directory to the filtered-parquet-PM folders\n",
    "os.chdir(filtered_parquet_PM_path)\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "65a29b0b-895a-4b0d-a1f5-902fa31f9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_parquet_PM_path_2 = ssd_path + 'filtered-parquet-PM 2/'\n",
    "filtered_parquet_PM_path_3 = ssd_path + 'filtered-parquet-PM 3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "78cb67fe-d79a-4c94-a215-c6f7a7a59a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2990"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(filtered_parquet_PM_path_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9f209b60-29f9-4196-b471-010aa0de0683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(filtered_parquet_PM_path_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f22ac81a-20bd-430b-b059-de67687363ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8552"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(filtered_parquet_PM_path_3)\n",
    "len(os.listdir('AAPL_1min_parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94a65d42-4129-4375-bf4d-03b1bd74409b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4146"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting how many folders with tickers there are\n",
    "len(os.listdir(filtered_parquet_PM_HL_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7dbfbf8e-73a0-47cf-a738-c26d5f81c250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the data with NTLA\n",
    "NTLA_parq_folder = 'NTLA_1min_parquet'\n",
    "len(os.listdir(NTLA_parq_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ce587102-745f-4734-8193-1003680eb53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=516</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-02 04:03:00</th>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-05 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18 00:00:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-11-18 15:59:00</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: repartition-merge, 8 graph layers</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                        Open     High      Low    Close   Volume  Ticker\n",
       "npartitions=516                                                         \n",
       "2017-11-02 04:03:00  float64  float64  float64  float64  float64  string\n",
       "2017-11-05 00:00:00      ...      ...      ...      ...      ...     ...\n",
       "...                      ...      ...      ...      ...      ...     ...\n",
       "2024-11-18 00:00:00      ...      ...      ...      ...      ...     ...\n",
       "2024-11-18 15:59:00      ...      ...      ...      ...      ...     ...\n",
       "Dask Name: repartition-merge, 8 graph layers"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing with dask NTLA filtered PM parquet data\n",
    "df_NTLA = dd.read_parquet(NTLA_parq_folder)\n",
    "\n",
    "\n",
    "# This part is optional (if you want to choose a specific datetime range)\n",
    "# ^Note, the time range you chose MUST have data in it for this to work\n",
    "# df_NTLA = df_NTLA.loc['2024-07-15 00:00':'2024-07-30 00:00']\n",
    "# df_NTLA = df_NTLA.loc['2024-12-01 00:00':'2024-12-30 00:00']\n",
    "\n",
    "# Need to do the following to repartition properly\n",
    "df_NTLA = df_NTLA.reset_index()\n",
    "df_NTLA['timestamp'] = df_NTLA['timestamp'].dt.floor('s')\n",
    "df_NTLA = df_NTLA.set_index('timestamp')\n",
    "\n",
    "# # Repartioning for 5 days because data is pretty sparse\n",
    "df_NTLA = df_NTLA.repartition(freq='5D')\n",
    "\n",
    "df_NTLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41ef9933-d7c8-45ef-a393-063781d2b1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-06-28 04:06:00</th>\n",
       "      <td>130.00</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>130.00</td>\n",
       "      <td>130.0000</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 04:07:00</th>\n",
       "      <td>125.00</td>\n",
       "      <td>125.0000</td>\n",
       "      <td>123.99</td>\n",
       "      <td>123.9900</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 04:08:00</th>\n",
       "      <td>123.99</td>\n",
       "      <td>123.9900</td>\n",
       "      <td>123.99</td>\n",
       "      <td>123.9900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 04:09:00</th>\n",
       "      <td>121.99</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>121.99</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-28 04:10:00</th>\n",
       "      <td>122.00</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>122.00</td>\n",
       "      <td>122.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30 15:55:00</th>\n",
       "      <td>163.65</td>\n",
       "      <td>163.9399</td>\n",
       "      <td>162.83</td>\n",
       "      <td>163.0200</td>\n",
       "      <td>37309.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30 15:56:00</th>\n",
       "      <td>163.21</td>\n",
       "      <td>163.4000</td>\n",
       "      <td>161.58</td>\n",
       "      <td>161.9499</td>\n",
       "      <td>58386.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30 15:57:00</th>\n",
       "      <td>161.91</td>\n",
       "      <td>162.2800</td>\n",
       "      <td>161.56</td>\n",
       "      <td>162.0700</td>\n",
       "      <td>80103.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30 15:58:00</th>\n",
       "      <td>162.11</td>\n",
       "      <td>162.5900</td>\n",
       "      <td>161.99</td>\n",
       "      <td>162.4199</td>\n",
       "      <td>63782.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06-30 15:59:00</th>\n",
       "      <td>162.42</td>\n",
       "      <td>162.5100</td>\n",
       "      <td>161.63</td>\n",
       "      <td>161.8199</td>\n",
       "      <td>123506.0</td>\n",
       "      <td>NTLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1419 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open      High     Low     Close    Volume Ticker\n",
       "timestamp                                                               \n",
       "2021-06-28 04:06:00  130.00  130.0000  130.00  130.0000     295.0   NTLA\n",
       "2021-06-28 04:07:00  125.00  125.0000  123.99  123.9900     238.0   NTLA\n",
       "2021-06-28 04:08:00  123.99  123.9900  123.99  123.9900       0.0   NTLA\n",
       "2021-06-28 04:09:00  121.99  122.0000  121.99  122.0000     200.0   NTLA\n",
       "2021-06-28 04:10:00  122.00  122.0000  122.00  122.0000       0.0   NTLA\n",
       "...                     ...       ...     ...       ...       ...    ...\n",
       "2021-06-30 15:55:00  163.65  163.9399  162.83  163.0200   37309.0   NTLA\n",
       "2021-06-30 15:56:00  163.21  163.4000  161.58  161.9499   58386.0   NTLA\n",
       "2021-06-30 15:57:00  161.91  162.2800  161.56  162.0700   80103.0   NTLA\n",
       "2021-06-30 15:58:00  162.11  162.5900  161.99  162.4199   63782.0   NTLA\n",
       "2021-06-30 15:59:00  162.42  162.5100  161.63  161.8199  123506.0   NTLA\n",
       "\n",
       "[1419 rows x 6 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NTLA.partitions[250:300].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c19d2d5-d765-424c-81dc-3fd81e1fc0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024-11-18    720\n",
       "2020-06-03    718\n",
       "2017-11-02    717\n",
       "2021-06-28    714\n",
       "2020-12-02    710\n",
       "2021-06-30    705\n",
       "2022-12-01    623\n",
       "2024-10-24    612\n",
       "2022-08-03    563\n",
       "2023-11-01    540\n",
       "2022-09-16    536\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NTLA = pd.read_parquet(NTLA_parq_folder)\n",
    "pd.DataFrame(df_NTLA.index.date).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f43a0a-3329-4ad8-a521-71fd514ac725",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e1d152-c1b8-476d-959e-61ace025be38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761c6d3-71bf-4015-b7bd-6cb73f58118e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
